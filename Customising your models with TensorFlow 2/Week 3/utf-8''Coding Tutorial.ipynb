{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
    " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
    " #### [3. The Embedding layer](#coding_tutorial_3)\n",
    " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
    " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
    " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element output\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with defaults\n",
    "imdb.load_data(path = 'imdb.npz', index_from = 3)\n",
    "\n",
    "# ~/.keras/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
       "         list([1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 2, 5, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 950, 5, 2, 15, 45, 629, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2, 7, 2, 861, 2, 5, 2, 30, 2, 2, 56, 4, 841, 5, 990, 692, 8, 4, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 565, 921, 2, 39, 4, 529, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 2]),\n",
       "         list([1, 111, 748, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 748, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 2, 2, 2, 2, 8, 847, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 993, 2, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 655, 2, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 2, 18, 631, 2, 797, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 656, 6, 2, 54, 2, 2, 98, 6, 2, 40, 558, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 711, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 930, 8, 508, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 584, 10, 10, 2, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 7, 819, 4, 22, 2, 17, 6, 2, 787, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 704, 7, 101, 999, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 910, 769, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 743, 46, 2, 9, 2, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 6, 2, 7, 470]),\n",
       "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 519, 2, 6, 769, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 718, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "\n",
    "imdb.load_data(num_words = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
       "         ...,\n",
       "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
       "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
       "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
       "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
       "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
       "         ...,\n",
       "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
       "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "\n",
    "imdb.load_data(num_words = 1000, skip_top = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 518, 21, 55, 1713, 6, 20, 716, 6, 65, 38, 73, 15, 12, 220, 461, 878, 14, 20, 716, 450, 537, 38, 73, 5189, 15, 12, 16, 4, 86, 171, 211, 6, 20, 13, 100, 24, 106, 8, 20252, 12, 16, 99, 147, 5, 4, 105, 38, 565, 15, 149, 12, 877, 6, 965, 1651, 319, 134, 289, 349, 5, 68, 2166, 855, 19, 68, 10082, 31, 11, 843, 400, 569, 72, 99, 254, 150, 13, 28, 296, 11, 94, 6274, 209, 21501, 450, 211, 5, 13, 923, 51, 13, 210, 6677, 14, 20, 9, 6, 991, 4, 487, 4, 116, 4, 10409, 7, 450, 537, 209, 112, 60, 4, 222, 227, 5303, 285, 44, 14, 20, 9, 3160, 1542, 1809, 2128, 57, 594, 12, 434, 215, 28, 1816, 98]),\n",
       "         list([1, 14, 22, 714, 8012, 4, 921, 2124, 4, 905, 1488, 5, 4, 350, 2501, 354, 7, 1691, 1612, 349, 13, 1610, 12, 23, 6, 13574, 5, 16, 2664, 15, 13, 69, 24, 557, 7, 12, 159, 10, 10, 13, 81, 24, 124, 48, 14, 16, 14513, 3667, 2016, 21, 4, 1794, 4, 8466, 5, 943, 7, 4, 105, 17, 73, 17, 4, 49, 1096, 370, 157, 3392, 4, 109, 33241, 299, 32, 1467, 6, 1249, 744, 10, 10, 4, 8466, 200, 1593, 5, 14513, 1367, 4, 172, 389, 1175, 75, 219, 11, 1513, 890, 19, 1593, 5, 1441, 6909, 6239, 9, 389, 11, 41, 105, 1302, 4182, 5, 13291, 6, 8022, 23, 41, 105, 11, 33, 297, 11, 4, 5322, 7, 4, 1635, 59, 9, 2227, 5, 246, 31, 70, 9530, 19, 41, 33, 4, 172, 58, 10, 10, 50, 26, 49, 388, 121, 13, 235, 4, 114, 9281, 6, 1229, 5, 4, 388, 200, 33241, 5, 27, 1233, 980, 220, 306, 398, 18, 160, 22, 33241, 266, 125, 17, 160, 109, 32, 295, 21, 148, 26, 1403, 5266, 10, 10, 14, 22, 215, 30, 448, 23, 6, 283, 65, 42, 215, 28, 77, 398, 34, 294, 37, 1452, 134, 2490, 13, 967, 12, 709, 46, 7, 6, 878, 158, 10, 10]),\n",
       "         list([1, 13, 219, 14, 20, 23, 248, 5, 447, 12, 13, 244, 6, 147, 1690, 22, 337, 5, 14, 31, 16, 87, 4, 177, 16, 93, 7, 49, 66, 221, 84, 8246, 9, 210, 87, 5, 1024, 31711, 9, 11, 6, 2756, 7, 27, 205, 29, 70, 297, 199, 212, 5, 708, 11, 4, 172, 20, 40, 171, 409, 70, 4, 65, 347, 9, 87, 99, 4, 197, 7, 112, 502, 8, 794, 6, 58, 347, 7, 51, 80, 593, 5, 8, 361, 14, 58, 347, 8, 3621, 6, 4564, 1690, 9, 35, 221, 326, 5, 14, 20, 961, 12, 46, 11, 141, 6, 96, 15, 9, 220, 484, 867])],\n",
       "        dtype=object), array([1, 0, 0, ..., 1, 1, 1])),\n",
       " (array([list([1, 14, 9, 31, 7, 4, 249, 108, 13, 28, 110, 11, 6, 137, 10, 10, 4, 439, 9, 15, 12, 152, 124, 726, 12, 494, 8, 30, 35, 1089, 993, 22, 43675, 42, 35, 3435, 9, 10528, 17, 6, 959, 12, 996, 23, 32, 6566, 10, 10, 4, 116, 9, 2526, 4, 2559, 125, 1489, 5, 4, 424, 3881, 1149, 10, 10, 14746, 8035, 9, 242, 4, 118, 155, 44, 14, 22, 21, 15, 218, 6, 52, 155, 252, 29, 47, 35, 1596, 5, 61226, 168, 21, 1116, 29, 191, 165, 511, 43, 168, 33, 89, 29, 12482, 54, 27, 4727, 889, 10, 10, 66, 92, 106, 14, 22, 49, 135, 12, 738, 3260, 4719, 13, 135, 31, 9, 99, 111]),\n",
       "         list([1, 4, 7591, 248, 7, 108, 5077, 28, 13, 421, 38, 117, 11728, 8, 105, 5077, 28, 13, 77, 93, 8, 4032, 34, 141, 3648, 414, 15670, 1316, 3264, 7678, 28837, 2161, 8464, 2986, 732, 12435, 61019, 46432, 798, 14, 22, 17, 48, 12, 71, 129, 24558]),\n",
       "         list([1, 160, 12576, 212, 270, 11, 4, 1547, 12, 186, 15, 4, 612, 31, 1622, 1466, 18, 1205, 16, 11, 14, 172, 719, 1547, 17, 38, 111, 7, 12563, 5, 71375, 108, 26, 270, 50, 5, 137, 14, 9, 246, 160, 31, 12, 9, 275, 195, 5, 73, 93, 15, 13, 131, 510, 12, 10, 10, 16866, 9, 928, 11, 6, 1155, 74, 644, 267, 5, 116, 7376, 30258, 13, 104, 442, 424, 8, 30, 6, 117, 1155, 151, 11, 41, 3992, 523, 59, 9, 99, 185, 8, 30, 928, 11, 349, 73, 16866, 127, 24, 1497, 41, 1417, 5, 515, 29, 5, 7376, 521, 245, 18, 49, 1356, 253, 183, 79, 2732, 54, 4, 3992, 106, 9, 2586, 16866, 659, 12, 5, 408, 12, 8, 7376, 17, 6, 3470, 5, 111, 712, 959, 10, 10, 542, 1794, 5, 4, 192, 15, 14, 20, 122, 24, 5390, 99, 76, 23, 706, 2764, 21, 6, 3793, 114, 97, 14, 6, 1036, 5, 737, 117, 22]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 0, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "\n",
    "imdb.load_data(maxlen = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use '1' as the character that indicates the start of a sequence\n",
    "\n",
    "imdb.load_data(start_char = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "\n",
    "imdb_word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "\n",
    "index_from = 3\n",
    "imdb_word_index = {key : value + index_from for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "\n",
    "imdb_word_index['lol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View an input sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb data set\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "\n",
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen = 300, padding = 'post', truncating = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "\n",
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "\n",
    "padded_x_train = np.expand_dims(padded_x_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Masking layer \n",
    "\n",
    "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype = 'float32')\n",
    "masking_layer = tf.keras.layers.Masking(mask_value = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass tf_x_train to it\n",
    "\n",
    "masked_x_train = masking_layer(tf_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7, shape=(25000, 300, 1), dtype=float32, numpy=\n",
       "array([[[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [2.200e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.940e+02],\n",
       "        [1.153e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.400e+01],\n",
       "        [4.700e+01],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.100e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.446e+03],\n",
       "        [7.079e+03],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]],\n",
       "\n",
       "       [[1.000e+00],\n",
       "        [1.700e+01],\n",
       "        [6.000e+00],\n",
       "        ...,\n",
       "        [0.000e+00],\n",
       "        [0.000e+00],\n",
       "        [0.000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "\n",
    "masked_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(25000, 300), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "\n",
    "masked_x_train._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim = 501, output_dim = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23, shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
       "array([[[[-0.02199105,  0.00718679,  0.00439936,  0.02761528,\n",
       "          -0.02744799,  0.04197438,  0.00121126,  0.00554336,\n",
       "          -0.01917312, -0.02417066, -0.01205728,  0.03286525,\n",
       "           0.02062018,  0.0333295 , -0.04439197, -0.02090738]],\n",
       "\n",
       "        [[-0.03738066, -0.03236242, -0.0333157 ,  0.03799558,\n",
       "           0.01554806, -0.03371681,  0.02362678,  0.00296945,\n",
       "          -0.02070389,  0.00452913, -0.02239439, -0.00662582,\n",
       "          -0.00390065,  0.03995811, -0.01064419,  0.01456117]],\n",
       "\n",
       "        [[ 0.02744159, -0.03137391,  0.03338529, -0.04215351,\n",
       "          -0.01051193, -0.02565799,  0.04960355, -0.01933267,\n",
       "           0.00447674, -0.02589325, -0.03840486, -0.02856342,\n",
       "           0.02282042,  0.0010585 ,  0.03552392, -0.01428783]],\n",
       "\n",
       "        [[-0.04662685,  0.0313133 ,  0.0262915 , -0.04169899,\n",
       "          -0.00404419, -0.01320643,  0.00656436,  0.03483099,\n",
       "          -0.01080004,  0.03560768, -0.0479215 , -0.00188339,\n",
       "           0.00343454, -0.02352013,  0.044041  ,  0.01544478]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indicies = tf.constant([[[0], [1], [5], [500]]])\n",
    "sequence_of_embeddings = embedding_layer(sequence_of_indicies) \n",
    "sequence_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02199105,  0.00718679,  0.00439936, ...,  0.0333295 ,\n",
       "        -0.04439197, -0.02090738],\n",
       "       [-0.03738066, -0.03236242, -0.0333157 , ...,  0.03995811,\n",
       "        -0.01064419,  0.01456117],\n",
       "       [ 0.00212038, -0.00244834,  0.03343621, ..., -0.04967605,\n",
       "         0.00142596, -0.00452946],\n",
       "       ...,\n",
       "       [ 0.02290111, -0.03545104, -0.01370822, ...,  0.02211941,\n",
       "        -0.02979032,  0.01371164],\n",
       "       [-0.0231654 , -0.03014958, -0.0410709 , ...,  0.01089624,\n",
       "         0.00244714,  0.02481407],\n",
       "       [-0.04662685,  0.0313133 ,  0.0262915 , ..., -0.02352013,\n",
       "         0.044041  ,  0.01544478]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "\n",
    "embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03019427,  0.03849204,  0.01379206, -0.04987701, -0.0196511 ,\n",
       "       -0.01316189, -0.04693884, -0.00068017,  0.02675762, -0.02658227,\n",
       "       -0.01654872,  0.01818875, -0.04031408,  0.01590068, -0.00496254,\n",
       "        0.03344745], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "\n",
    "embedding_layer.get_weights()[0][14, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layer that uses the mask_zero kwarg\n",
    "\n",
    "masking_embedding_layer = tf.keras.layers.Embedding(input_dim = 500, output_dim = 16, mask_zero = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first dataset example sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "        tf.keras.layers.Embedding(input_dim = max_index_value + 1, output_dim = embedding_dim, mask_zero = False),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.4775 - accuracy: 0.8382 - val_loss: 0.0119 - val_accuracy: 0.8109\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 32s 1ms/sample - loss: 0.4399 - accuracy: 0.8535 - val_loss: 0.0111 - val_accuracy: 0.8359\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.4071 - accuracy: 0.8649 - val_loss: 0.0105 - val_accuracy: 0.8469\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 33s 1ms/sample - loss: 0.3800 - accuracy: 0.8722 - val_loss: 0.0099 - val_accuracy: 0.8422\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.3576 - accuracy: 0.8784 - val_loss: 0.0093 - val_accuracy: 0.8656\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 5, batch_size = 32, validation_data = (x_test, y_test), validation_steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "\n",
    "weights = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/vecs.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-07d4ece34681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mout_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vecs.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mout_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vecs.tsv'"
     ]
    }
   ],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "\n",
    "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "\n",
    "simplernn_layer = tf.keras.layers.SimpleRNN(units = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.recurrent.SimpleRNN at 0x7f0514aa2b00>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "\n",
    "simplernn_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim = max_index_value + 1, output_dim = embedding_dim, mask_zero = False),\n",
    "        tf.keras.layers.LSTM(units = 16),\n",
    "        tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/5\n",
      " 1504/25000 [>.............................] - ETA: 7:56 - loss: 0.6920 - accuracy: 0.5027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-424206d3026e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model and save its training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the corresponding label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim = max_index_value + 1, output_dim = embedding_dim, mask_zero = False),\n",
    "        tf.keras.layers.LSTM(units = 16, return_sequences = True),\n",
    "        tf.keras.layers.LSTM(units = 32, return_sequences = False),\n",
    "\n",
    "        tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim = max_index_value + 1, output_dim = embedding_dim, mask_zero = False),\n",
    "        tf.keras.layers.Bidirectional(layer = tf.keras.layers.LSTM(units = 8), merge_mode = 'sum',\n",
    "                                     backward_layer = tf.keras.layers.GRU(units = 8, go_backwards = True)),\n",
    "\n",
    "        tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim = max_index_value + 1, output_dim = embedding_dim, mask_zero = False),\n",
    "        tf.keras.layers.Bidirectional(layer = tf.keras.layers.LSTM(units = 8, return_sequences = True), merge_mode = 'concat'),\n",
    "        tf.keras.layers.GRU(units = 8, return_sequences = False),\n",
    "\n",
    "        tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "   32/25000 [..............................] - ETA: 7:04:50 - loss: 0.6931 - accuracy: 0.4062"
     ]
    }
   ],
   "source": [
    "# Train the model, saving its history\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
